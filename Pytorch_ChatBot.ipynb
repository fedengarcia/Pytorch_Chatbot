{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "339457cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\feden\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Importamos dataset y dataloader, para procesar los datos para ingresarlos a los modelos\n",
    "# Nos permite usar nuestros datos para generar nuestro mdoelo de entrenamiento, agrupa los ejemplos con sus respectivas etiquetas.\n",
    "# Dataloader, convierte dataset a un objeto iterable para pytorch, nos permite realizar nuestros propios minibatches de forma automatica \n",
    "# De forma simple con dataloader\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import random\n",
    "import json\n",
    "import string\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2699211",
   "metadata": {},
   "source": [
    "### DEFINE NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f0a4aca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.l1 = nn.Linear(input_size, hidden_size) \n",
    "        self.l2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.l3 = nn.Linear(hidden_size, hidden_size) \n",
    "        self.l4 = nn.Linear(hidden_size, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        out = self.l3(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.l4(out)\n",
    "        # no activation and no softmax at the end\n",
    "        return out\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e1c15b",
   "metadata": {},
   "source": [
    "### Methods\n",
    "    For clean data\n",
    "    Tokenize sentence\n",
    "    Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "00876a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#REMOVE ACCENTS\n",
    "def removeAccents(word):\n",
    "    translation = str.maketrans(\"áéíóúüàèìùò\", \"aeiouuaeiou\")\n",
    "    return word.translate(translation)\n",
    "\n",
    "\n",
    "#REMOVE PUNCTUATION AND SINGS\n",
    "def removePunctuation (word):\n",
    "    word = word.translate(str.maketrans('', '', string.punctuation))   \n",
    "    return word\n",
    "\n",
    "\n",
    "#TOKENIZE WORDS\n",
    "def tokenize(sentence):\n",
    "    return nltk.word_tokenize(sentence)\n",
    "\n",
    "# BAG OF WORDS\n",
    "def bag_of_words(tokenized_sentence, words):\n",
    "    \"\"\"\n",
    "    return bag of words array:\n",
    "    1 for each known word that exists in the sentence, 0 otherwise\n",
    "    example:\n",
    "    sentence = [\"hello\", \"how\", \"are\", \"you\"]\n",
    "    words = [\"hi\", \"hello\", \"I\", \"you\", \"bye\", \"thank\", \"cool\"]\n",
    "    bog   = [  0 ,    1 ,    0 ,   1 ,    0 ,    0 ,      0]\n",
    "    \"\"\"\n",
    "\n",
    "    # initialize bag with 0 for each word\n",
    "    bag = np.zeros(len(words), dtype=np.float32)\n",
    "    for idx, w in enumerate(words):\n",
    "        if w in tokenized_sentence: \n",
    "            bag[idx] = 1\n",
    "\n",
    "    return bag\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0d1531",
   "metadata": {},
   "source": [
    "### LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a43bc6a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56 patterns: [(['hola'], 'CC_HOLA'), (['hi'], 'CC_HOLA'), (['hello'], 'CC_HOLA'), (['ciao'], 'CC_HOLA'), (['buen', 'dia'], 'CC_HOLA'), (['buenas', 'tardes'], 'CC_HOLA'), (['buenas', 'noches'], 'CC_HOLA'), (['hey'], 'CC_HOLA'), (['whats', 'up'], 'CC_HOLA'), (['que', 'onda'], 'CC_HOLA'), (['hola', 'que', 'tal'], 'CC_HOLA'), (['hola', 'amigo'], 'CC_HOLA'), (['hola', 'holaa'], 'CC_HOLA'), (['cya'], 'CC_ADIOS'), (['nos', 'vemos'], 'CC_ADIOS'), (['Goodbye'], 'CC_ADIOS'), (['chau'], 'CC_ADIOS'), (['adios'], 'CC_ADIOS'), (['hasta', 'luego'], 'CC_ADIOS'), (['me', 'voy'], 'CC_ADIOS'), (['Cuantos', 'anios'], 'CC_EDAD'), (['Cuantos', 'aÃ±os', 'tenes'], 'CC_EDAD'), (['cual', 'es', 'tu', 'edad'], 'CC_EDAD'), (['que', 'tan', 'viejo', 'eres'], 'CC_EDAD'), (['edad', '?'], 'CC_EDAD'), (['tu', 'edad'], 'CC_EDAD'), (['dime', 'tus', 'aÃ±os'], 'CC_EDAD'), (['como', 'te', 'apodaron'], 'CC_NAME_BOT'), (['como', 'te', 'llamas'], 'CC_NAME_BOT'), (['cual', 'es', 'tu', 'nombre'], 'CC_NAME_BOT'), (['como', 'te', 'dicen'], 'CC_NAME_BOT'), (['tenes', 'un', 'nombre'], 'CC_NAME_BOT'), (['decime', 'tu', 'nombre'], 'CC_NAME_BOT'), (['tu', 'nombre', 'como', 'es'], 'CC_NAME_BOT'), (['quien', 'sos'], 'CC_NAME_BOT'), (['que', 'haces'], 'CC_PARA_QUE_FUE_CREADO'), (['para', 'que', 'te', 'crearon'], 'CC_PARA_QUE_FUE_CREADO'), (['cual', 'es', 'tu', 'funcion'], 'CC_PARA_QUE_FUE_CREADO'), (['a', 'que', 'te', 'dedicas'], 'CC_PARA_QUE_FUE_CREADO'), (['con', 'que', 'me', 'puedes', 'ayudar'], 'CC_PARA_QUE_FUE_CREADO'), (['para', 'que', 'sirves'], 'CC_PARA_QUE_FUE_CREADO'), (['que', 'haces', 'para', 'vivir'], 'CC_PARA_QUE_FUE_CREADO'), (['cual', 'es', 'tu', 'objetivo'], 'CC_PARA_QUE_FUE_CREADO'), (['como', 'estas'], 'CC_COMO_ESTAS'), (['como', 'te', 'sientes', 'hoy'], 'CC_COMO_ESTAS'), (['cual', 'es', 'tu', 'humor'], 'CC_COMO_ESTAS'), (['estas', 'contento'], 'CC_COMO_ESTAS'), (['sos', 'feliz'], 'CC_COMO_ESTAS'), (['como', 'andas'], 'CC_COMO_ESTAS'), (['estas', 'chevere'], 'CC_COMO_ESTAS'), (['clima', 'de', 'hoy'], 'CC_EL_CLIMA'), (['hace', 'frio'], 'CC_EL_CLIMA'), (['hace', 'calor'], 'CC_EL_CLIMA'), (['que', 'temperatura', 'hay', 'aqui'], 'CC_EL_CLIMA'), (['quiero', 'saber', 'si', 'hace', 'frio', 'o', 'calor'], 'CC_EL_CLIMA'), (['como', 'esta', 'el', 'dia'], 'CC_EL_CLIMA')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('chitchat_intents.json', 'r') as f:\n",
    "    intents = json.load(f)\n",
    "\n",
    "all_words = []\n",
    "tags = []\n",
    "xy = []\n",
    "\n",
    "for intent in intents['intents']:\n",
    "        tag = intent['tag']\n",
    "        \n",
    "        # add to tag list\n",
    "        tags.append(tag)\n",
    "        for pattern in intent['patterns']:\n",
    "            \n",
    "            #Clean data\n",
    "            # tokenize each word in the sentence\n",
    "            words = tokenize(pattern)\n",
    "            \n",
    "            # Remove accents\n",
    "            w = [removeAccents(word) for word in words]\n",
    "\n",
    "            # Remove punctuation\n",
    "            w = [removePunctuation(word) for word in words]\n",
    "\n",
    "            # Remove empty slots    \n",
    "            w = [word for word in words if word != '']\n",
    "            \n",
    "            # add to our words list\n",
    "            all_words.extend(words)\n",
    "            \n",
    "            # add to xy pair\n",
    "            xy.append((words, tag))\n",
    "\n",
    "# Remove duplicates and sort\n",
    "all_words = sorted(set(all_words))\n",
    "tags = sorted(set(tags))\n",
    "\n",
    "\n",
    "print(f\"{len(xy)} patterns: {xy}\\n\")\n",
    "# print(len(tags), \"tags:\", tags)\n",
    "# print(\"\")\n",
    "# print(len(all_words), \" words:\", all_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50e6df8",
   "metadata": {},
   "source": [
    "### Prepare Data for model\n",
    "    80% of the dataset will be for train the model\n",
    "    20% of the dataset will be for testing the model\n",
    "    We can use random_split from Pytorch or Split the data manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "70de6e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------CREATING TESTING DATA--------------------\n",
      "\n",
      "\n",
      "--------------- TESTING DATA CREATED--------------------\n",
      "\n",
      "\n",
      "---------------CREATING TRAINING DATA--------------------\n",
      "\n",
      "\n",
      "--------------- TRAIN DATA CREATED--------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# number_rows = len(xy)    # The size of our dataset or the number of rows in excel table.  \n",
    "# test_split = int(number_rows*0.2)  \n",
    "# train_split = number_rows - test_split     \n",
    "# train_set, test_set = random_split(xy, [train_split, test_split])   \n",
    "\n",
    "\n",
    "print(\"\\n---------------CREATING TESTING DATA--------------------\\n\")\n",
    "# Create testing data\n",
    "# Data for training\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "# Data for testing the model\n",
    "test_array = []\n",
    "percentage = int(len(xy)*0.2)\n",
    "\n",
    "for i in range(percentage):\n",
    "#     item = dataset_copy.pop(random.randrange(len(xy)))\n",
    "    item = xy.pop(random.randrange(len(xy)))\n",
    "    test_array.append(item)\n",
    "    bag = bag_of_words(item[0], all_words)\n",
    "    x_test.append(bag)\n",
    "    label = tags.index(item[1])\n",
    "    y_test.append(label)\n",
    "\n",
    "\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "print(\"\\n--------------- TESTING DATA CREATED--------------------\\n\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n---------------CREATING TRAINING DATA--------------------\\n\")\n",
    "# Create training data\n",
    "# Data for training\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for (pattern_sentence, tag) in xy:\n",
    "    # X: bag of words for each pattern_sentence\n",
    "    bag = bag_of_words(pattern_sentence, all_words)\n",
    "    x_train.append(bag)\n",
    "    # y: PyTorch CrossEntropyLoss needs only class labels, not one-hot\n",
    "    label = tags.index(tag)\n",
    "    y_train.append(label)\n",
    "\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "print(\"\\n--------------- TRAIN DATA CREATED--------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239d2391",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c073c80c",
   "metadata": {},
   "source": [
    "### DEFINE CLASSES FOR DATASET\n",
    "    Train Dataset\n",
    "    Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "57131add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Class Dataset\n",
    "class TrainDataset(Dataset):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.n_samples = len(x_train)\n",
    "        self.x_data = x_train\n",
    "        self.y_data = y_train\n",
    "\n",
    "    # support indexing such that dataset[i] can be used to get i-th sample\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    # we can call len(dataset) to return the size\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "    \n",
    "# Test Class Dataset\n",
    "class TestDataset(Dataset):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.n_samples = len(x_test)\n",
    "        self.x_data = x_test\n",
    "        self.y_data = y_test\n",
    "\n",
    "    # support indexing such that dataset[i] can be used to get i-th sample\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    # we can call len(dataset) to return the size\n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed108849",
   "metadata": {},
   "source": [
    "### TRAINING THE MODEL\n",
    "    Define Hyper Parameters\n",
    "        Epochs,\n",
    "        Batch_size,\n",
    "        Learning_rate,\n",
    "        input, hidden, output sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2e430551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------- TRAINING DATA --------------------\n",
      "\n",
      "Epoch [100/1000], Loss: 0.3762\n",
      "Epoch [200/1000], Loss: 0.0243\n",
      "Epoch [300/1000], Loss: 0.0060\n",
      "Epoch [400/1000], Loss: 0.0016\n",
      "Epoch [500/1000], Loss: 0.0010\n",
      "Epoch [600/1000], Loss: 0.0002\n",
      "Epoch [700/1000], Loss: 0.0003\n",
      "Epoch [800/1000], Loss: 0.0000\n",
      "Epoch [900/1000], Loss: 0.0001\n",
      "Epoch [1000/1000], Loss: 0.0000\n",
      "\n",
      "Final loss: 0.0000\n",
      "\n",
      "training complete. file saved to data.pth\n"
     ]
    }
   ],
   "source": [
    "# Hyper-parameters \n",
    "num_epochs = 1000\n",
    "batch_size = 8\n",
    "learning_rate = 0.001\n",
    "input_size = len(x_train[0])\n",
    "hidden_size = 8\n",
    "output_size = len(tags)\n",
    "\n",
    "# Define Train Loader\n",
    "train_set = TrainDataset()\n",
    "train_loader = DataLoader(dataset = train_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "# Define Test Loader\n",
    "test_set = TestDataset()\n",
    "test_loader = DataLoader(dataset = test_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "model.eval()\n",
    "test_loss, correct = 0, 0\n",
    "size = len(test_loader.dataset)\n",
    "\n",
    "# Select device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Create neural network\n",
    "model = NeuralNet(input_size, hidden_size, output_size).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "print(\"\\n--------------- TRAINING DATA --------------------\\n\")\n",
    "for epoch in range(num_epochs):\n",
    "    for (words, labels) in train_loader:\n",
    "            words = words.to(device)\n",
    "            labels = labels.to(dtype=torch.long).to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(words)\n",
    "\n",
    "            # if y would be one-hot, we must apply\n",
    "            # labels = torch.max(labels, 1)[1]\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 100 == 0:\n",
    "            print (f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "    \n",
    "\n",
    "print(f'\\nFinal loss: {loss.item():.4f}\\n')\n",
    "\n",
    "trained_data = {\n",
    "        \"model_state\": model.state_dict(),\n",
    "        \"input_size\": input_size,\n",
    "        \"hidden_size\": hidden_size,\n",
    "        \"output_size\": output_size,\n",
    "        \"all_words\": all_words,\n",
    "        \"tags\": tags\n",
    "}\n",
    "\n",
    "FILE = \"data.pth\"\n",
    "torch.save(trained_data, FILE)\n",
    "\n",
    "print(f'training complete. file saved to {FILE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bbe91e",
   "metadata": {},
   "source": [
    "### TEST MODEL\n",
    "    With pytroch lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "5f4df2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------- TESTING DATA --------------------\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.679010 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.5%, Avg loss: 0.898093 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.580189 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.684455 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.697466 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.765797 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.816899 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.612771 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.544695 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.543839 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.924733 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.897536 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.891080 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.937306 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.619568 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.549113 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.540895 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.888064 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.730004 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.597835 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.003585 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.804458 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.783329 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.600834 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.896040 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.076184 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.777116 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.923060 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.828892 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.609919 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.893530 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.928553 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.794661 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.847577 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.608352 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.586702 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.999115 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.623649 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.584541 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.886284 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.578884 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.889651 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.726612 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.087542 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.949137 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.590898 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.752476 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.593409 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.863967 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.613991 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.902670 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.109549 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.819667 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.604692 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.898034 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.894639 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.037607 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.636008 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.691433 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.083145 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.814403 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.958554 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.626716 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.584924 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.893462 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.618096 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.549541 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.747284 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.810994 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.027174 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.910781 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.927042 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.622872 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.795442 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.595112 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.686127 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.868150 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.894643 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.941513 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.655418 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.550003 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.891198 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.928690 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.898030 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.615677 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.545571 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.578855 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.719001 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.919558 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.656265 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.761214 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.921073 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.935898 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.728330 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.589779 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.689223 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.589404 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.580667 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.889274 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.652479 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.763647 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.598685 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.720484 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.912508 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.624133 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.553351 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.855315 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.824015 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.888613 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.793848 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.778412 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.923222 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.584014 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.583660 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.855319 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.789174 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.950243 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.764847 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.560455 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.892482 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.787096 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.597736 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.863919 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.583742 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.858408 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.617370 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.583167 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.789890 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.748459 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.807473 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.743527 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.768477 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.746200 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.742998 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.913327 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.792758 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.745332 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.603654 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.900960 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.895153 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.576326 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.854403 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.610052 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.040436 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.847466 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.935616 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.581973 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.691325 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.588649 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.572908 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.785529 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.744429 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.561665 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.783128 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.600702 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.616408 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.863175 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.750468 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.914155 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.796357 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.925465 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.794297 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.710607 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.700586 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.590513 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.607876 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.754599 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.914777 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.936794 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.902710 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.611599 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.719043 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.736525 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.741788 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.056903 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.957616 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.619029 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.893651 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.798145 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.599095 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.757564 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.628780 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.581420 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.684609 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.871605 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.619609 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.890668 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.753927 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.911531 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.896475 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.963656 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.053492 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.746503 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.627375 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.796005 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.881445 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.789361 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.024447 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.623738 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.724634 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.907441 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.895374 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.614755 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.752381 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.744188 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.775700 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.913653 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.612966 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.103998 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.637756 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.579475 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.684366 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.731612 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.812626 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.818678 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.928427 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.622361 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.756409 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.776639 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.739673 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.123910 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.612767 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.859151 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.923666 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.112003 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.606928 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.854754 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.718776 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.701585 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.703198 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.702887 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.737583 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.948951 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.970216 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.047054 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.813141 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.924090 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.587178 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.890688 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.825274 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.749804 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.914072 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.827597 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.096498 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.644076 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.902934 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.799134 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.602296 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.001064 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.736453 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.560551 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.682001 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.700773 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.706593 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.017768 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.664779 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.899788 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.619058 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.756414 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.558983 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.886145 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.617664 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.006481 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.629039 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.615770 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.006244 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.625107 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.577465 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.578768 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.858492 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.722834 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.705759 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.870582 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.794672 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.912551 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.074174 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.820711 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.242549 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.869235 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.642716 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.766607 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.629910 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.585635 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.751818 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.604465 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.721796 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.803145 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.575727 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.687489 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.799445 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.786369 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.918642 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.764659 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.912444 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.939976 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.943589 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.729858 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.947986 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.730259 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.876893 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.581184 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.751851 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.562475 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.565991 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.570098 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.853818 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.574803 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.543958 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.061066 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.643120 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.544821 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.993880 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.596514 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.580560 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.719237 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.701247 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.590467 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.787747 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.600702 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.857643 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.571637 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.683215 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.731468 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.594267 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.685626 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.014558 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.630049 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.694279 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.558892 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.538378 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.573293 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.854046 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.919973 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.761063 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.920636 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.794089 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.567166 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.067022 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.775948 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.128444 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.648069 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.112460 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.642480 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.794248 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.571388 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.892359 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.932480 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.615738 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.893829 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.726716 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.562947 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.569695 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.067928 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.779729 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.712871 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.626249 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.795381 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.885452 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.617160 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.548717 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.537084 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.604693 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.901089 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.929326 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.584093 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.859136 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.613699 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.722779 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.736585 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.804993 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.754527 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.631873 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.690327 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.588524 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.760004 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.843245 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.926341 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.618615 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.798501 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.916503 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.764874 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.745332 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.803031 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.599139 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.581477 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.032790 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.808108 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.569625 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.539302 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.928240 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.829368 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.785930 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.744886 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.596534 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.931320 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.799187 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.610386 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.040478 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.912422 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.616886 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.614668 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.548406 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.786134 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.605163 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.550808 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.889197 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.579761 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.547804 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.747656 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.708980 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.771394 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.920951 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.793733 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.571302 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.574235 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.683122 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.735219 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.914327 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.828229 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.641258 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.901093 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.933401 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.735842 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.595381 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.788361 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.632629 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.550651 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.786243 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.717448 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.082752 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.645831 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.699896 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.080558 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.810606 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.747970 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.810908 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.783622 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.026808 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.159802 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.967400 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.736330 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.881832 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.613629 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.755885 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.916910 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.618014 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.545350 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.997613 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.596809 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.214561 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.620337 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.863153 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.889860 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.582900 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.548196 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.683512 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.622997 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.760646 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.781520 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.573024 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.000901 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.627935 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.867694 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.894608 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.610586 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.722990 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.912821 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.651660 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.221417 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.764609 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.918001 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.900874 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.584865 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.545364 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.894091 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.579689 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.544740 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.850454 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.608540 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.793651 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.915897 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.043760 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.809673 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.815148 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.639033 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.617437 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.576357 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.997822 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.631624 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.694358 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.947622 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.901008 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.723969 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.769528 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.878747 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.721186 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.911084 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.732882 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.595011 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.757053 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.884251 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.923726 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.939992 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.113626 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.680523 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.010865 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.805390 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.783468 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.596671 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.546156 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.064814 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.815896 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.601165 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.750682 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.875802 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.615471 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.587003 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.583863 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.575923 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.757840 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.710135 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.700109 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.773363 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.810180 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.600032 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.864206 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.037470 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.741593 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.878846 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.616869 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.755723 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.593225 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.856097 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.816854 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.747755 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.565041 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.689626 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.908628 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.899725 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.622953 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.549954 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.719056 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.049988 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.955775 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.591728 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.887183 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.859142 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.138844 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.641511 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.013224 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.741469 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.021539 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.629926 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.543590 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.571178 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.897489 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.720451 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.803394 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.715924 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.086206 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.638180 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.008628 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.843490 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.608376 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.722285 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.090592 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.639241 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.869107 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.787819 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.846722 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.720656 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.876228 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.755766 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.094777 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.643744 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.080775 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.641993 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.699416 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.590261 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.542277 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.099235 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.749314 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.950418 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.737380 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.909441 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.651238 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.583638 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.544527 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.609386 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.862320 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.614686 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.727147 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.873278 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.105286 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.787989 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.815911 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.880877 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.578015 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.893187 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.794420 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.714708 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.771426 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.916774 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.828513 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.817073 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.716950 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.950446 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.583237 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.688427 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.795918 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.571746 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.690636 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.694594 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.796689 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.640906 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.587127 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.752423 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.593809 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.791638 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.567471 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.067650 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.130001 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.920139 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.928234 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.731017 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.563462 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.538509 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.780823 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.776195 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.814124 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.576928 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.687639 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.766928 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.746178 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.053378 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.952436 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.979882 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.944933 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.803966 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.715901 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.772164 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.739114 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.568141 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.756867 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.628693 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.078893 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.957309 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.619419 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.074143 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.602366 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.694463 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.582490 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.858935 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.793806 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.781997 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.090798 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.639290 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.691649 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.869012 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.577143 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.754937 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.593694 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.900304 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.791719 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.919311 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.079093 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.607143 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.613033 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.541061 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.746642 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.803172 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.060502 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.953327 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.905312 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.615569 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.544851 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.679867 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.552888 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.603173 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.106847 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.609928 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.579063 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.606445 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.824050 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.785800 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.883665 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.616936 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.859479 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.579713 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.902147 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.929459 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.619434 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.580252 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.789525 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.566789 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.570026 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.689831 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.592536 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.753099 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.883928 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.940174 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.620751 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.618914 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.576124 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.683776 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.700877 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.552041 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.684410 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.626871 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.757368 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.740320 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.560639 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.716318 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.871506 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.720258 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.872394 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.619708 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.863610 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.135328 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.614195 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.583188 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.758748 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.559275 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.720050 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.914532 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.582415 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.036981 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.741383 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.909964 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.830846 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.960609 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.731814 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.598061 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.864377 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.968874 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.593388 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.682438 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.936901 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.896001 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.754593 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.604983 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.543528 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.679679 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.771399 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.918872 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.651999 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.546349 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.095671 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.957894 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.735142 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.020748 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.774260 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.909999 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.899190 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.901601 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.584807 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.541006 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.781135 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.709574 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.871230 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.615382 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.544828 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.566841 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.893280 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.075840 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.602556 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.687251 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.799822 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.606391 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.726111 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.594187 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.756361 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.600540 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.582081 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.715331 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.775855 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.919429 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.617751 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.890413 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.610628 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.578562 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.540814 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.887948 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.579070 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.722212 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.776126 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.810932 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.569978 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.539175 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.567153 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.063943 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.812025 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.608399 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.755253 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.773021 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.921154 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.618373 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.070345 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.126864 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.958126 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.765832 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.881169 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.896270 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.614974 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.722520 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.919998 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.768902 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.567685 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.546713 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.885029 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.936549 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.110140 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.750699 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.596777 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.584666 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.104534 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.959002 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.591960 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.899498 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.139814 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.645877 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.548640 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.889032 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.828712 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.610067 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.793252 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.785424 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.129629 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.927233 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.936250 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.654589 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.728468 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.740781 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.878037 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.935257 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.728839 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.594045 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.856811 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.824201 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.889172 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.107691 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.928081 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.112726 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.642491 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.586725 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.611069 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.107835 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.064256 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.775625 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.845198 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.574166 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.539847 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.566807 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.570607 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.031431 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.775596 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.057055 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.607466 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.586420 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.759570 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.593684 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.545877 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.683757 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.588303 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.002811 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.662491 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.012256 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.909087 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.939557 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.585543 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.924789 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.829537 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.916909 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.893502 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.587022 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.890646 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.726736 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.915368 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.927615 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.622365 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.693318 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.079736 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.603483 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.690936 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.875569 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.612280 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.897299 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.829263 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.575936 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.997792 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.596296 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.900629 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.894963 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.611026 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.582857 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.540784 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.753448 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.562108 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.576571 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.687572 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.764956 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.912481 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.620473 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.618879 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.217320 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.689305 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.554657 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.711903 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.918671 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.824676 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.919357 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.901044 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.580558 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.854514 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.932735 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.588677 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.572344 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.888233 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.582719 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.998639 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.592757 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.753298 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.876547 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.755806 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.740124 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.768052 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.564105 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.852897 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.787585 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.573782 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.574663 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.892597 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.934000 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.616506 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.587132 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.890253 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.579893 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.575320 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.582573 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.890090 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.828255 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.606472 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.578631 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.544414 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.850414 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.784916 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.954868 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.936649 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.899443 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.973258 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.118202 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.607680 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.889154 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.576165 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.691017 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.803789 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.097018 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.812663 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.887023 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.897024 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.577149 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.857583 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.247158 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.834486 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.614798 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.544777 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.743633 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.557386 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.569000 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.853509 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.575205 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.750910 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.811276 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.030854 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.121928 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.674325 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.798229 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.745845 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.592986 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.685443 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.772119 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.565031 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.000073 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.811448 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.600758 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.004539 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.846741 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.788614 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.877465 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.581939 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.583230 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.748440 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.914319 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.585979 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.723559 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.769477 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.602180 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.823517 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.570867 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.896861 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "model.eval()\n",
    "test_loss, correct = 0, 0\n",
    "size = len(test_loader.dataset)\n",
    "\n",
    "print(\"\\n--------------- TESTING DATA --------------------\\n\")\n",
    "for epoch in range(num_epochs):\n",
    "    with torch.no_grad():\n",
    "        for (pattern, label) in test_loader:\n",
    "                pattern = pattern.to(device)\n",
    "                label = label.to(dtype=torch.long).to(device)\n",
    "\n",
    "                pred = model(pattern)\n",
    "\n",
    "                test_loss += loss_fn(pred, label).item()\n",
    "                correct += (pred.argmax(1) == label).type(torch.float).sum().item()\n",
    "                \n",
    "        test_loss /= batch_size\n",
    "        correct /= size\n",
    "        print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3e4ef9",
   "metadata": {},
   "source": [
    "### TEST MODEL\n",
    "    Testing Manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9ba9591d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EJEMPLO: ['a', 'que', 'te', 'dedicas'] - Intencion:CC_PARA_QUE_FUE_CREADO\n",
      "PREDICCION:\n",
      " Intencion:CC_HOLA\n",
      " Confianza:0.9993878602981567 \n",
      "\n",
      "EJEMPLO: ['que', 'onda'] - Intencion:CC_HOLA\n",
      "PREDICCION:\n",
      " Intencion:CC_PARA_QUE_FUE_CREADO\n",
      " Confianza:0.9986312985420227 \n",
      "\n",
      "EJEMPLO: ['hola', 'amigo'] - Intencion:CC_HOLA\n",
      "PREDICCION:\n",
      " Intencion:CC_HOLA\n",
      " Confianza:0.9999898672103882 \n",
      "\n",
      "EJEMPLO: ['sos', 'feliz'] - Intencion:CC_COMO_ESTAS\n",
      "PREDICCION:\n",
      " Intencion:CC_NAME_BOT\n",
      " Confianza:0.6260813474655151 \n",
      "\n",
      "EJEMPLO: ['cual', 'es', 'tu', 'funcion'] - Intencion:CC_PARA_QUE_FUE_CREADO\n",
      "PREDICCION:\n",
      " Intencion:CC_HOLA\n",
      " Confianza:0.989615797996521 \n",
      "\n",
      "EJEMPLO: ['hey'] - Intencion:CC_HOLA\n",
      "PREDICCION:\n",
      " Intencion:CC_ADIOS\n",
      " Confianza:0.6899569630622864 \n",
      "\n",
      "EJEMPLO: ['cual', 'es', 'tu', 'nombre'] - Intencion:CC_NAME_BOT\n",
      "PREDICCION:\n",
      " Intencion:CC_NAME_BOT\n",
      " Confianza:0.8743694424629211 \n",
      "\n",
      "EJEMPLO: ['estas', 'contento'] - Intencion:CC_COMO_ESTAS\n",
      "PREDICCION:\n",
      " Intencion:CC_COMO_ESTAS\n",
      " Confianza:0.8686397075653076 \n",
      "\n",
      "EJEMPLO: ['estas', 'chevere'] - Intencion:CC_COMO_ESTAS\n",
      "PREDICCION:\n",
      " Intencion:CC_COMO_ESTAS\n",
      " Confianza:0.8885152339935303 \n",
      "\n",
      "EJEMPLO: ['tu', 'edad'] - Intencion:CC_EDAD\n",
      "PREDICCION:\n",
      " Intencion:CC_EDAD\n",
      " Confianza:0.9991281628608704 \n",
      "\n",
      "EJEMPLO: ['nos', 'vemos'] - Intencion:CC_ADIOS\n",
      "PREDICCION:\n",
      " Intencion:CC_ADIOS\n",
      " Confianza:0.7578557729721069 \n",
      "\n",
      "Accuracy de tu modelo: 0.5286638975143433\n",
      "6/11 acertadas\n",
      "Clasifico correctamente el 60% de los ejemplos para testing\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "correcta = 0\n",
    "with torch.no_grad():\n",
    "    for item in test_array:\n",
    "\n",
    "        #Clean data\n",
    "        # tokenize each word in the sentence\n",
    "        pattern = item[0]\n",
    "        \n",
    "        # Remove accents\n",
    "        pattern = [removeAccents(word) for word in pattern]\n",
    "\n",
    "        # Remove punctuation\n",
    "        pattern = [removePunctuation(word) for word in pattern]\n",
    "\n",
    "        # Remove empty slots    \n",
    "        pattern = [word for word in pattern if word != '']\n",
    "            \n",
    "\n",
    "        X = bag_of_words(pattern, all_words)\n",
    "        X = X.reshape(1, X.shape[0])\n",
    "        X = torch.from_numpy(X).to(device)\n",
    "\n",
    "        output = model(X)\n",
    "        _, predicted = torch.max(output, dim=1)\n",
    "        \n",
    "        tag = tags[predicted.item()]\n",
    "\n",
    "        probs = torch.softmax(output, dim=1)\n",
    "        prob = probs[0][predicted.item()]\n",
    "        \n",
    "        print(f\"EJEMPLO: {item[0]} - Intencion:{item[1]}\")\n",
    "        print(f\"PREDICCION:\\n Intencion:{tag}\\n Confianza:{prob.item()} \\n\")\n",
    "        total += prob.item()\n",
    "        if(tag == item[1]):\n",
    "            correcta += 1\n",
    "            \n",
    "print(\"Accuracy de tu modelo:\",((total / len(test_array) * int(correcta/0.1)) / 100))\n",
    "print(f\"{correcta}/{len(test_array)} acertadas\")\n",
    "print(f\"Clasifico correctamente el {int(correcta/0.1)}% de los ejemplos para testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e78266",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eefbea3d",
   "metadata": {},
   "source": [
    "### CHAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "dd0a3b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hola! hablemos un rato... (type 'quit' to exit)\n",
      "Tu: hola\n",
      "Confianza:0.9999779462814331 -> Intencion:CC_HOLA\n",
      "WAMAC: Hola, me alegra verte de nuevo por aqui\n",
      "Tu: que haces\n",
      "Confianza:0.999941349029541 -> Intencion:CC_PARA_QUE_FUE_CREADO\n",
      "WAMAC: Fui creado para resolver dudas.\n",
      "Tu: como te llamas\n",
      "Confianza:0.9999778270721436 -> Intencion:CC_NAME_BOT\n",
      "WAMAC: Seguro tu me puedes ayudar con eso... era WAMAC, verdad?\n",
      "Tu: tu nombre\n",
      "Confianza:0.9980487823486328 -> Intencion:CC_NAME_BOT\n",
      "WAMAC: No se si ya me pusieron mi nombre, pero escuche rumores de que me llamo WAMAC.\n",
      "Tu: nombre\n",
      "Confianza:0.9943636655807495 -> Intencion:CC_NAME_BOT\n",
      "WAMAC: No se si ya me pusieron mi nombre, pero escuche rumores de que me llamo WAMAC.\n",
      "Tu: que frio hace hoy\n",
      "Confianza:0.9999954700469971 -> Intencion:CC_EL_CLIMA\n",
      "WAMAC: Pues no se, no he aprendido sobre el clima todavia\n",
      "Tu: hola quiero saber la temperatura\n",
      "Confianza:0.8324239253997803 -> Intencion:CC_ADIOS\n",
      "WAMAC: Adios!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "with open('chitchat_intents.json', 'r') as json_data:\n",
    "    intents = json.load(json_data)\n",
    "\n",
    "FILE = \"data.pth\"\n",
    "data = torch.load(FILE)\n",
    "\n",
    "input_size = data[\"input_size\"]\n",
    "hidden_size = data[\"hidden_size\"]\n",
    "output_size = data[\"output_size\"]\n",
    "all_words = data['all_words']\n",
    "tags = data['tags']\n",
    "model_state = data[\"model_state\"]\n",
    "\n",
    "model = NeuralNet(input_size, hidden_size, output_size).to(device)\n",
    "model.load_state_dict(model_state)\n",
    "model.eval()\n",
    "\n",
    "bot_name = \"WAMAC\"\n",
    "print(\"Hola! hablemos un rato... (type 'quit' to exit)\")\n",
    "while True:\n",
    "    sentence = input(\"Tu: \")\n",
    "\n",
    "    sentence = tokenize(sentence)\n",
    "    X = bag_of_words(sentence, all_words)\n",
    "    X = X.reshape(1, X.shape[0])\n",
    "    X = torch.from_numpy(X).to(device)\n",
    "\n",
    "    output = model(X)\n",
    "    _, predicted = torch.max(output, dim=1)\n",
    "\n",
    "    tag = tags[predicted.item()]\n",
    "\n",
    "    probs = torch.softmax(output, dim=1)\n",
    "    prob = probs[0][predicted.item()]\n",
    "    print(f\"Confianza:{prob.item()} -> Intencion:{tag}\")\n",
    "\n",
    "    if prob.item() > 0.7:\n",
    "        for intent in intents['intents']:\n",
    "            if tag == intent[\"tag\"]:\n",
    "                print(f\"{bot_name}: {random.choice(intent['responses'])}\")\n",
    "        if tag == \"CC_ADIOS\":\n",
    "            break\n",
    "    else:\n",
    "        print(f\"{bot_name}: No te entendi...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eb06c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c397da84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89958903",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1194f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9c9a7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
